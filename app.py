import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader

# --- SAYFA AYARLARI ---
st.set_page_config(page_title="BTÃœ AsistanÄ±", layout="centered")

# --- BTÃœ LOGOSU VE MODERN TASARIM CSS ---
st.markdown("""
    <style>
    /* Streamlit'in gereksiz parÃ§alarÄ±nÄ± gizle */
    header, footer, .stDeployButton, [data-testid="stStatusWidget"], button[title="View fullscreen"] {
        display: none !important;
        visibility: hidden !important;
    }

    /* Modern Balonlar */
    [data-testid="stChatMessage"] {
        border-radius: 20px;
        margin-bottom: 15px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    }
    
    /* Asistan Balonu (BTÃœ KÄ±rmÄ±zÄ±sÄ± Ã‡izgi) */
    [data-testid="stChatMessage"]:nth-child(odd) {
        background-color: #ffffff;
        border-left: 5px solid #d32f2f;
    }

    /* KullanÄ±cÄ± Balonu */
    [data-testid="stChatMessage"]:nth-child(even) {
        background-color: #f0f7ff;
        border-right: 5px solid #007bff;
    }
    </style>
    """, unsafe_allow_html=True)

# --- API KURULUMU ---
try:
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
    else:
        st.error("âš ï¸ API AnahtarÄ± BulunamadÄ±! LÃ¼tfen Secrets ayarlarÄ±nÄ± kontrol edin.")
        st.stop()
except Exception as e:
    st.error(f"API HatasÄ±: {e}")

# --- PDF OKUMA ---
@st.cache_data
def load_pdf():
    text = ""
    try:
        with open("bilgiler.pdf", "rb") as f:
            pdf_reader = PdfReader(f)
            for page in pdf_reader.pages:
                text += page.extract_text()
        return text
    except FileNotFoundError:
        return "" 

context = load_pdf()

# --- SOHBET GEÃ‡MÄ°ÅÄ° ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# KarÅŸÄ±lama EkranÄ± (Sadece mesaj yoksa gÃ¶ster)
if not st.session_state.messages:
    st.markdown("### ğŸ¤– BTÃœ Ã–ÄŸrenci Ä°ÅŸleri AsistanÄ±")
    st.write("Merhaba! Ben Bursa Teknik Ãœniversitesi asistanÄ±yÄ±m. Size nasÄ±l yardÄ±mcÄ± olabilirim?")
    
    c1, c2 = st.columns(2)
    if c1.button("ğŸ“‘ Ders AÃ§ma Ä°ÅŸlemleri"):
        st.session_state.pending_prompt = "BÃ¶lÃ¼mÃ¼mde ders aÃ§mak istiyorum, ne yapmalÄ±yÄ±m?"
    if c2.button("ğŸ“… SÄ±nav Tarihleri"):
        st.session_state.pending_prompt = "KÄ±sa sÄ±nav tarihimi nasÄ±l Ã¶ÄŸrenebilirim?"

# GeÃ§miÅŸ MesajlarÄ± Ekrana Bas
btu_logo = "https://btu.edu.tr/dosyalar/btu/dosyalar/BTU_Logo_Yatay_TR_Siyah(1).png"

for message in st.session_state.messages:
    avatar_img = btu_logo if message["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(message["role"], avatar=avatar_img):
        st.markdown(message["content"])

# --- SORGULAMA MANTIÄI ---
prompt = st.chat_input("Sorunuzu buraya yazÄ±n...")

if "pending_prompt" in st.session_state:
    prompt = st.session_state.pending_prompt
    del st.session_state.pending_prompt

if prompt:
    # 1. KullanÄ±cÄ± mesajÄ±nÄ± ekle ve gÃ¶ster
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)

    # 2. Cevap Ãœretimi
    with st.spinner("CevaplanÄ±yor..."):
        # BaÄŸlamÄ± kÄ±salt (Hata riskini azaltÄ±r)
        limited_context = context[:30000] if context else ""
        
        sys_instr = f"""
        Sen BTÃœ asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki bilgilere gÃ¶re cevap ver.
        Bilgiler: {limited_context}
        EÄŸer bilgide yoksa genel bilgini kullan ama bunu belirt.
        Asla 'metne gÃ¶re' veya 'baÄŸlama gÃ¶re' deme. DoÄŸal ve yardÄ±msever konuÅŸ.
        """
        
        # SENÄ°N Ä°STEDÄ°ÄÄ°N GÄ°BÄ°: 2.0 Flash Ä°LK SIRADA
        selected_models = [
            'models/gemini-2.0-flash',       # En hÄ±zlÄ± ve yeni
            'models/gemini-1.5-flash',       # Yedek (Ã‡ok kararlÄ±)
            'models/gemini-pro'              # Son Ã§are
        ]
        
        response_text = ""
        last_error = ""

        for m_name in selected_models:
            try:
                model = genai.GenerativeModel(m_name)
                response = model.generate_content(f"{sys_instr}\n\nSoru: {prompt}")
                
                if response and response.text:
                    response_text = response.text
                    break # BaÅŸarÄ±lÄ± olduysa dÃ¶ngÃ¼den Ã§Ä±k
            except Exception as e:
                last_error = str(e)
                continue # Hata alÄ±rsan sessizce diÄŸer modele geÃ§

    # 3. Sonucu Ekrana Bas
    if response_text:
        with st.chat_message("assistant", avatar=btu_logo):
            st.markdown(response_text)
        st.session_state.messages.append({"role": "assistant", "content": response_text})
        # st.rerun() komutunu kaldÄ±rdÄ±m, artÄ±k cevap kaybolmayacak!
    else:
        st.error(f"ÃœzgÃ¼nÃ¼m, ÅŸu an baÄŸlantÄ± kurulamadÄ±. Hata detayÄ±: {last_error}")
