import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader


st.set_page_config(page_title="ODB AsistanÄ±", layout="centered")


st.markdown("""
    <style>
    header, footer, .stDeployButton, [data-testid="stStatusWidget"], button[title="View fullscreen"] {
        display: none !important;
        visibility: hidden !important;
    }
    [data-testid="stChatMessage"] {
        border-radius: 20px;
        margin-bottom: 15px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    }
    [data-testid="stChatMessage"]:nth-child(odd) { background-color: #ffffff; border-left: 5px solid #d32f2f; }
    [data-testid="stChatMessage"]:nth-child(even) { background-color: #f0f7ff; border-right: 5px solid #007bff; }
    </style>
    """, unsafe_allow_html=True)


try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except:
    st.error("API HatasÄ±!")

@st.cache_data
def load_pdf():
    text = ""
    try:
        with open("bilgiler.pdf", "rb") as f:
            pdf_reader = PdfReader(f)
            for page in pdf_reader.pages:
                text += page.extract_text()
        return text
    except: return ""

context = load_pdf()


btu_logo = "https://depo.btu.edu.tr/img/sayfa//1691132554_284ffd9ee8d6a4286478.png"


if "messages" not in st.session_state:
    st.session_state.messages = []


for message in st.session_state.messages:
    avatar = btu_logo if message["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])


prompt = st.chat_input("Sorunuzu buraya yazÄ±n...")


if "pending_prompt" in st.session_state:
    prompt = st.session_state.pending_prompt
    del st.session_state.pending_prompt

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)

    with st.spinner("CevaplanÄ±yor..."):
        
        sys_instr = f"Sen BTÃœ asistanÄ±sÄ±n. Sadece ÅŸu bilgilere odaklan: {context[:15000]}. Bilgi yoksa genel bilgini kullan ama doÄŸal cevap ver."
        
        try:
            
            model = genai.GenerativeModel('models/gemini-2.0-flash')
            response = model.generate_content(f"{sys_instr}\n\nSoru: {prompt}")
            
            if response and response.text:
                answer = response.text
                with st.chat_message("assistant", avatar=btu_logo):
                    st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
                # Not: st.rerun() burada bazen hataya sebep olur, streamlit zaten input gelince yeniler.
            else:
                st.error("Model cevap Ã¼retemedi.")
        except Exception as e:
            st.error(f"Hata oluÅŸtu: {str(e)}")


if not st.session_state.messages:
    st.info("Merhaba! Size nasÄ±l yardÄ±mcÄ± olabilirim?")
    if st.button("ğŸ“‘ Ders AÃ§ma Ä°ÅŸlemleri HakkÄ±nda Bilgi"):
        st.session_state.pending_prompt = "BÃ¶lÃ¼mÃ¼mde ders aÃ§mak istiyorum, ne yapmalÄ±yÄ±m?"
      #  st.rerun()

